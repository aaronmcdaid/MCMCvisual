&nbsp;

<div style="border:1px solid black ; text-align:center">

# [Aaron McDaid](https://aaronmcdaid.github.io/)

Statistics and C++, and other fun projects

`aaron.mcdaid@gmail.com`

[`@aaronmcdaid`](https://twitter.com/aaronmcdaid)
</div>

# &nbsp;

# *Unit information priors and model selection*
<div style="text-align:right">
***by [Aaron](https://aaronmcdaid.github.io/), 29th October 2017***
</div>

# &nbsp;

This is the first in a series of posts I hope to wrote on model selection and the use of *unit information priors*.
I don't claim any great novelty in this post, I'm just writing up some simple experiments I'm doing to help me develop more intuition.

The basic issue is that you have two models and an observed dataset which you know was generated from one of those two models,
and you want to estimate ("select") which of the models was used to generate the dataset.

This post will use some very simple examples, for which there are often other simple methods
to estimate ("select") which model was used, but I focus on using unit information priors as
they can often be easily extended to more complex models.

## The Neyman-Pearson lemma

We have a sample of $n$ numbers drawn from distribution $X$, where $X$ is either
$H_1$ or $H_2$. I.e. Normally distributed with mean zero and variance equal to $1$ or $2$:

$$ H_1 : x_i \sim \mathcal{N}(0,1) $$
$$ H_2 : x_i \sim \mathcal{N}(0,2) $$

Given a vector of observations, $\mathbf{x}$, we can compute its probability density (*likelihood*) under the two hypotheses
in a straightforward manner.
$$
\mathrm{P}(\mathbf{x} | H_1) = \prod_{i=1}^n \mathcal{N}( x_i ; 0,1 )
$$
$$
\mathrm{P}(\mathbf{x} | H_2) = \prod_{i=1}^n \mathcal{N}( x_i ; 0,2 )
$$

where we define the following to compute the density of one observation, $x$, under a given mean and variance:
$$
\mathcal{N}( x ; \mu,\sigma^2 ) = \frac1{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

A very simple approach is to simply say that if $\mathrm{P}(\mathbf{x} | H_1)>\mathrm{P}(\mathbf{x} | H_2)$
then we select model $1$ as the true model, i.e. $\sigma^2 = 1$.
Otherwise, if $\mathrm{P}(\mathbf{x} | H_1)<\mathrm{P}(\mathbf{x} | H_2)$
then we select model $2$ as the true model, i.e. $\sigma^2 = 2$.

More generally, we can compute the ratio of these two probability densities and also define a threshold.
When the ratio is greater than the threshold, we select $H_1$, otherwise we select $H_2$.
$$
\frac{\mathrm{P}(\mathbf{x} | H_1)}{\mathrm{P}(\mathbf{x} | H_2)}
$$
A higher or lower threshold can be set if you wish to control the error rates in a frequentist manner.
Perhaps you want to assume $H_1$ in general and only select $H_2$ (reject $H_1$) when the evidence
is very strong. This would require a very low threshold, much less than $1.0$.

This is essentially the [Nayman-Pearson lemma](https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma);
when given two *point* hypotheses, you simply compute the probability of the data under both models
and compare the two probabilities. The likelihoods are *sufficient statistics* and you can (and should) throw away the data
and use only the two *likelihoods* to select a model.

For simplicity, I will use a threshold of $1.0$ in the remainder of this document.
In other words, we simply select the model which has the larger likelihood.

$H_1$ and $H_2$ are called *point* hypotheses because the all the model parameters (mean and variance) are known
and therefore the density can be calculated exactly from the observed data $\mathbf{x}$

## (non-)Point hypotheses

But what if $H_2$ is replaced with $H_\theta$, with unknown $\theta$?
$$ H_\theta : x_i \sim \mathcal{N}(0,\theta) $$

In this case, if we don't know exactly what $\theta$ is, we cannot compute
$\mathrm{P}(\mathbf{x} | H_\theta)$.
Given a dataset which we know was draw from $H_1$ or $H_\theta$, how do we select which of those was the true model?

## Naive approach, via an estimate $\hat\theta$

Given an observed vector $\mathrm{x}$, we can estimate its variance as the variance which maximizes
$\mathrm{P}(\mathbf{x} | H_\theta)$. This is the [Maximum Likelihood Estimate (MLE)](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation):

$$
\hat\theta
=
\underset{\theta}{\operatorname{argmax}}{~} \mathrm{P}(\mathbf{x} | H_\theta)
~~~~~~~~~~
$$
$$
=
\underset{\theta}{\operatorname{argmax}}{~}
\prod_{i=1}^n \mathcal{N}( x_i ; 0,\theta )
$$

As we can't compute the exact $\mathrm{P}(\mathbf{x} | H_\theta)$,
we instead estimate it via $\mathrm{P}(\mathbf{x} | H_{\hat\theta})$.

**Note that I use $\mathrm{\hat{P}}$ to emphasize that this is merely an estimate
of the probability density.**

$$
\mathrm{\hat{P}}(\mathbf{x} | H_\theta) = \mathrm{P}(\mathbf{x} | H_{\hat\theta})
$$

It would be tempting now to compare
$\mathrm{\hat{P}}(\mathbf{x} | H_\theta)$
to
$\mathrm{     P }(\mathbf{x} | H_1)$
and use that to decide whether to select $H_1$ or $H_\theta$.
However, is is guaranteed to always select $H_\theta$!
By construction, the $\hat\theta$ is the value which maximizes the likelihood and
therefore the likelihood under $\sigma^2 = \hat\theta$ is guaranteed to be at least
as large as that under $H_1$:

$$
\mathrm{P}(\mathbf{x} | H_{\hat\theta}) > \mathrm{     P }(\mathbf{x} | H_1)
$$
(Equality is not possible in that, as $\hat\theta$ will never be exactly equal to $1$)

So yes, we do want to estimate
$\mathrm{P}(\mathbf{x} | H_{\theta})$,
but
$\mathrm{\hat{P}}(\mathbf{x} | H_{\hat\theta})$
is a very biased estimate of that and is therefore useless as is.

Before proceeding, I should note that the [BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion)
or [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion) can be used to adjust
these estimates and reduce the bias. Go head and read those links, they are interesting!
But this post is about another approach.



## priors

How do we resolve this, and use an estimate $\mathrm{P}(\mathbf{x} | H_\theta)$ that is less biased?

Before proceeding, let's define $\tau = \frac1{\sigma^2}$, the inverse of the *variance*.
This is known as the *precision* and is often easier to work with mathematically.
We can now refer to a Normal distribution as $\mathcal{N}(\mu,\tau^{-1})$,
which is equivalent to $\mathcal{N}(\mu,\sigma^2)$.

We don't know the true $\tau$, but let's assume we know it was drawn from a
Gamma distribution:
$$
\tau \sim \mathcal{Gamma}(\alpha,\beta)
$$

If $\alpha$ and $\beta$ are known, we can compute
$$
\int_\Gamma \mathrm{P}(\mathbf{x} | H_{\theta{=}\tau^{-1}})
$$

&nbsp;

&nbsp;
<div style="text-align:right">
***by [Aaron](https://aaronmcdaid.github.io/), 29th October 2017***
</div>
